{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-0d386c27-77e0-4cbd-b708-2c1f2af77e67",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4547,
    "execution_start": 1636951157266,
    "source_hash": "21206ee7",
    "tags": []
   },
   "source": [
    "# PANNA Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-8ffbee25-1744-4d2b-a3ab-9e1f8ea1ab39",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Part 2 - Training and validation\n",
    "\n",
    "<div>\n",
    "<div style=\"float: right\">\n",
    "<img src=\"./figs/Fig5_FC_atomic_NN.png\" width=\"250\">\n",
    "</div>\n",
    "<div>\n",
    "<p>\n",
    "\n",
    "\n",
    "Once we have the data, we can start the supervised learning process with a neural network. PANNA is built on a TensorFlow engine for training and validating a neural network. In a standard use case, we interact with this engine only via PANNA python scripts and simple configuration files.\n",
    "\n",
    "**This step has three, mostly concurrent parts:**\n",
    "\n",
    "- Setting up a network architecture and hyperparameters\n",
    "- Training and visualization of training\n",
    "- Validation and testing\n",
    "\n",
    "\n",
    "In this tutorial we will go through the simplest neural network type, i.e. a fully connected atomic network, where we have a fully-connected sub network for each atomic species, each sub network processes the G-vectors belonging to atoms of that species, and the total energy is calculated as a sum of all network outputs. \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "In this part of the tutorial tensorflow (version 2.xx) will be needed.\n",
    "Check the next cell to setup your environment and uncomment the relative sections if you need to install packages. If you are using Google colab, you can mount your drive and you can use the version magic to specify the tensorflow version before importing it.\n",
    "Plotting at the end of the tutorial will also require pandas and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANNA is installed correctly\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the absolute path to PANNA (or leave this relative path)\n",
    "panna_dir = os.path.abspath('../..')\n",
    "\n",
    "# In case you need to mount the drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# panna_dir = '/content/drive/MyDrive/your_path_to_panna'\n",
    "\n",
    "# Cleaning up path for command line\n",
    "panna_cmdir = panna_dir.replace(' ', '\\ ')\n",
    "\n",
    "# Check if PANNA is installed, otherwise install it\n",
    "try:\n",
    "  import panna\n",
    "  print(\"PANNA is installed correctly\")\n",
    "except ModuleNotFoundError:\n",
    "  print(\"PANNA not found, attempting to install\")\n",
    "  !pip install panna_cmdir\n",
    "\n",
    "# If you want to install tensorflow, pandas or matplotlib\n",
    "# !pip install tensorflow>=2\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-cdb1b37c-8e7d-4e2d-adcd-23062de6008b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Part 2a - Setting up a network architecture\n",
    "\n",
    "In PANNA, we set up a network architecture and hyperparameters in a configuration file, which is then used with the training script called ``train.py``. \n",
    "\n",
    "The configuration file holds other important information as well, e.g. I/O details such as where to log the training information and how frequently and parallelization details.\n",
    "\n",
    "Let's take a look at a minimal sample training configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00003-c37f9ce2-cdf2-453c-9dbd-ea070c6509ec",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 645,
    "execution_start": 1636945503355,
    "source_hash": "9ce2a505",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IO_INFORMATION]\r\n",
      "data_dir = ./tutorial_data/train\r\n",
      "train_dir = ./mytrain\r\n",
      "log_frequency = 100\r\n",
      "save_checkpoint_steps = 500\r\n",
      "\r\n",
      "[DATA_INFORMATION]\r\n",
      "atomic_sequence = H, C, O, N\r\n",
      "output_offset = -13.62, -1029.41, -2041.84, -1484.87\r\n",
      "\r\n",
      "[TRAINING_PARAMETERS]\r\n",
      "batch_size = 20\r\n",
      "learning_rate = 0.01\r\n",
      "steps_per_epoch = 100\r\n",
      "max_epochs = 10\r\n",
      "\r\n",
      "[DEFAULT_NETWORK]\r\n",
      "g_size = 384\r\n",
      "architecture = 128:32:1\r\n",
      "trainable = 1:1:1\r\n"
     ]
    }
   ],
   "source": [
    "!cat {panna_cmdir+'/doc/tutorial/input_files/mytrain.ini'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-a55db8bf-c783-42dd-9719-927eb1a0df78",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Now we have defined a simple fully-connected network**, which is made up of 4 atomic networks (one for each species). By defeault each species network has the same architecture: 2 hidden layers of 128 and 32 nodes, 1 output node, and all nodes are trainable, i.e. no layer is frozen. \n",
    "\n",
    "**We have also set some parameters for the trainig.** These sample parameters are going to result in a relatively short training (not very realistic for a production run!). At every step the learning is going to take place by using a loss/cost function using 20 configurations (as dictated by ``batch_size`` key). To determine how long the training will run, we define an \"epoch\" as a set of 100 steps, and require the code to perform 10 epochs of optimization, resulting in 1000 optimization steps (in theory an epoch is defined as the time to use each example in the training set once, but we can also choose it to be an arbitrary number).\n",
    "\n",
    "**Note that we have not specified all the parameters we can here, we are relying on the defaults**. As you get more proficient with generation of NN potentials you can experiment with them all, e.g. different activation functions, training algorithms, fuctional forms for the loss function beyond the quadratic RMSE formula, regularization etc.\n",
    "\n",
    "**PANNA is based on the TF engine.** So if a new activation function, or a fancy new training algorithm is available in TF, it is available in PANNA. Furthermore, we have also implemented several options that are only relevant for the atomistic simulation community, e.g. per-atom loss functions, Gaussian activation function to ensure smoothness of the final NN potential etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-85f65633-1e3c-4aed-af66-0c6b35cebdf7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Part 2b Training and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00006-14e7222d-64ee-4ad0-908e-5c8c7d4c6e3f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19627,
    "execution_start": 1637000609012,
    "source_hash": "5e4ad847",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-23 11:40:10.479446: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-04-23 11:40:10.479507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-04-23 11:40:10.479513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "INFO - \n",
      "    ____   _    _   _ _   _    _           \n",
      "   |  _ \\ / \\  | \\ | | \\ | |  / \\     \n",
      "   | |_) / _ \\ |  \\| |  \\| | / _ \\     \n",
      "   |  __/ ___ \\| |\\  | |\\  |/ ___ \\    \n",
      "   |_| /_/   \\_\\_| \\_|_| \\_/_/   \\_\\ \n",
      "\n",
      " Properties from Artificial Neural Network Architectures\n",
      "\n",
      "INFO - reading ./input_files/mytrain.ini\n",
      "INFO - Found a default network!\n",
      "INFO - This network size will be used as default for all species unless specified otherwise\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 4s 7ms/step - tot_st: 100.0000 - MAE/at: 0.1493\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 5ms/step - tot_st: 200.0000 - MAE/at: 0.0279\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 6ms/step - tot_st: 300.0000 - MAE/at: 0.0225\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 5ms/step - tot_st: 400.0000 - MAE/at: 0.0226\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 6ms/step - tot_st: 500.0000 - MAE/at: 0.0174\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 6ms/step - tot_st: 600.0000 - MAE/at: 0.0137\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 5ms/step - tot_st: 700.0000 - MAE/at: 0.0113\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 5ms/step - tot_st: 800.0000 - MAE/at: 0.0153\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 6ms/step - tot_st: 900.0000 - MAE/at: 0.0134\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 8ms/step - tot_st: 1000.0000 - MAE/at: 0.0106\n"
     ]
    }
   ],
   "source": [
    "# Let us run a mock training case:\n",
    "!cd {panna_cmdir+'/doc/tutorial/'}; python {panna_cmdir+'/src/panna/train.py'} --config ./input_files/mytrain.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-3b4d14cb-5a25-4573-b974-698d4779e8e8",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This was a NN training for 1000 steps, 20 configurations in each batch. The total data we used was 900 configurations from H2O, NH3 and CH4 molecules, 300 configurations each. Configurations are taken from the ANI dataset and total energy calculations performed with Quantum Espresso, as we have done before in Part 1 of this tutorial.\n",
    "\n",
    "We don't expect a reliable NN potential from this train, as for each species we are training a network of size ~(384 x 128) = 50k parameters, for 4 species this means a 200k parameter network, with considerably small amount of data. However, the training speed per batch does not change with the data size so even this small exercise is enough to show us how rapid the TF engine works, without even flexing with the parallelization algorithms available.\n",
    "\n",
    "**Training speed is relevant for scientific applications**, because finding the right G-vector parameters, network architecture etc. can take many training trial and error iterations. Furthermore, this also allows us to build multiple networks for a single system and use committee-learning as a (very!) simplified approximation for error bar of our network predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-6d231576-3952-4d47-aa8e-e02a76f8d874",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The training step has a few outputs to pay attention to, in the directory we specified as ``train_dir`` in the configuration file, for this example ``doc/tutorial/mytrain``:\n",
    "\n",
    "As a default, the code writes to command line the error during training as the mean absolute error (MAE) per atom in the simulation. We can also access this data, computed once per epoch, in the file ``metrics.dat`` in the training directory.\n",
    "\n",
    "In the subfolder ``_models`` in the same directory, we can find the neural network information as multiple 'checkpoints' i.e. snapshots of the network saved during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00012-6b546a10-cf54-4f8c-82e0-89e597698d7d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1185,
    "execution_start": 1637000731344,
    "source_hash": "f491e3f5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch MAE/at tot_st\n",
      "0 0.039821624755859375 100\n",
      "1 0.03187663108110428 200\n",
      "2 0.012678883969783783 300\n",
      "3 0.019117996096611023 400\n",
      "4 0.009907471016049385 500\n",
      "5 0.017504841089248657 600\n",
      "6 0.016212349757552147 700\n",
      "7 0.01463889516890049 800\n",
      "8 0.017903482541441917 900\n",
      "9 0.013020811602473259 1000\n",
      "checkpoint\t\t\t\tepoch_5_step_500.data-00000-of-00001\n",
      "epoch_10_step_1000.data-00000-of-00001\tepoch_5_step_500.index\n",
      "epoch_10_step_1000.index\n"
     ]
    }
   ],
   "source": [
    "!cat {panna_cmdir+'/doc/tutorial/mytrain/metrics.dat'}\n",
    "!ls {panna_cmdir+'/doc/tutorial/mytrain/_models'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-4327b430-de4b-4b7e-a2a2-e6326fbf9f29",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "One very useful TF tool for monitoring training is called tensorboard, which allows us to visualize the training process through multiple metrics.\n",
    "\n",
    "The command in the next cell will start tensorboard pointing at your training directory.\n",
    "If you're running on your local machine, this can then be opened in a browser by navigating to http://0.0.0.0:8080/.\n",
    "\n",
    "Stop the execution of the cell once you're done exploring the board.\n",
    "\n",
    "If you're running this in a remote environement such as Deepnote you might be able to access tensorboard by allowing incoming connection. E.g. for deepnote:\n",
    "* Go to environment tab\n",
    "* Allow incoming connections\n",
    "* Copy the link you see there, which is where the visualizations will be served:\n",
    "\n",
    "If you're running in Google colab, you should be able to use Tensorboard directly in the notebook by using the magics below instead of the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00014-12268463-5950-43a7-b214-b68df38a5912",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 390594,
    "execution_start": 1637000773042,
    "source_hash": "5e0dce36",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-30 12:08:33.969564: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-30 12:08:33.969605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-30 12:08:33.969611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.11.0 at http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={panna_cmdir+'/doc/tutorial/mytrain'} --host=0.0.0.0 --port=8080\n",
    "\n",
    "# If you want to run in browser use the following magics instead\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {panna_cmdir+'/doc/tutorial/mytrain'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-57d1e888-0afa-4936-910d-a3dec0743b2a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Tensorboard allows us to visualize training as it goes on. It is useful to visualize multiple metrics at once and intervene as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-0a4528c0-3373-4e35-ba1b-68f2b56f5c00",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Part 2c Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-36174822-83ca-4898-80cc-066b0445d6dd",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We use the word \"validation\" here in its meaning in the machine learning community, i.e. **\"does the model perform similarly on a dataset that was not used in the training?\"**\n",
    "\n",
    "Validation of the neural network can be done as the training continues by using the snapshots of the network that are stored during training, aka \"checkpoints\".  \n",
    "\n",
    "Tensorflow also allows an automated validation embedded in the training, i.e. it stops the training at every X steps to evaluate the network on validation dataset. Here, to have more control, we will run validation manually instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-1407b121-8d7a-4357-b270-971aaa9363cd",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The data we will use for validation purposes are placed in ``panna_data/tutorial/mytrain_val`` directory. Like the training step, the data are in tfr format, i.e. structures are converted to G-vectors and packaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00019-03286889-eb30-406d-b3f9-42c4c728a4b1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 783,
    "execution_start": 1636947015290,
    "source_hash": "ab1960a3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-2-10.tfrecord  train-5-10.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "!ls {panna_cmdir+'/doc/tutorial/tutorial_data/validate'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-598fab89-20fc-4cce-b500-282ad7b94953",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The python script we will use for validation is called ``evaluate.py``. It takes a configuration file to identify important information, e.g. which neural network and data to use in validation and where to find them. Let's see a minimal sample configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00020-fb364b5a-0855-44ce-a425-73a9b58a7203",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 614,
    "execution_start": 1636947092814,
    "source_hash": "1c13aff3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IO_INFORMATION]\r\n",
      "data_dir = ./tutorial_data/validate\r\n",
      "train_ini = ./input_files/mytrain.ini\r\n",
      "networks_dir = ./mytrain/_models\r\n",
      "eval_dir = ./myvalidation\r\n",
      "\r\n",
      "[VALIDATION_OPTIONS]\r\n",
      "single_step = True \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat {panna_cmdir+'/doc/tutorial/input_files/myvalidation.ini'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-7c67cca6-4cdc-45c1-adad-e807e51571c5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The ``[IO_INFORMATION]`` section of the configuration file should point to where to find the stored networks (\"checkpoints\" saved while training) and ``[VALIDATION_OPTIONS]`` section gives us control about whether to evaluate every checkpoint, or just the last step of the training or a network that was produced at a particular training step we wish to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00022-d0aba9ec-3057-49e4-8e1e-a76bfb2e2412",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6997,
    "execution_start": 1637001212131,
    "source_hash": "401eb0f1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-30 12:08:51.516486: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-30 12:08:51.516528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-30 12:08:51.516534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "INFO - \n",
      "    ____   _    _   _ _   _    _           \n",
      "   |  _ \\ / \\  | \\ | | \\ | |  / \\     \n",
      "   | |_) / _ \\ |  \\| |  \\| | / _ \\     \n",
      "   |  __/ ___ \\| |\\  | |\\  |/ ___ \\    \n",
      "   |_| /_/   \\_\\_| \\_|_| \\_/_/   \\_\\ \n",
      "\n",
      " Properties from Artificial Neural Network Architectures\n",
      "\n",
      "INFO - reading ./input_files/myvalidation.ini\n",
      "INFO - reading ./input_files/mytrain.ini\n",
      "INFO - evaluating last checkpoint\n",
      "INFO - Found a default network!\n",
      "INFO - This network size will be used as default for all species unless specified otherwise\n",
      "INFO - ----start evaluation----\n",
      "INFO - validating network: 1/1, epoch: 10 step: 1000\n",
      "180/180 [==============================] - 1s 2ms/step\n",
      "INFO - eval time = 0.88 s\n",
      "INFO - file names are not available\n",
      "INFO - write time = 0.00 s\n"
     ]
    }
   ],
   "source": [
    "!cd {panna_cmdir+'/doc/tutorial/'}; python {panna_cmdir+'/src/panna/evaluate.py'} --config ./input_files/myvalidation.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-d5f0f47f-50b4-444f-816e-00e60ac75710",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The validation ends rapidly, as we have only one network to validate on a small dataset. The results are in the directory we specified in the configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00027-9043a435-a9a7-434a-837b-45e7517d694a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 844,
    "execution_start": 1637001240684,
    "source_hash": "f10a3994",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_10_step_1000.dat\r\n"
     ]
    }
   ],
   "source": [
    "!ls {panna_cmdir+'/doc/tutorial/myvalidation'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00028-89987a2d-e589-4220-9c13-e4c5a010b647",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 753,
    "execution_start": 1636951342046,
    "source_hash": "a3b79da1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#filename n_atoms e_ref e_nn\r\n",
      "N.A. 3 -2078.14306640625 -2078.103271484375\r\n",
      "N.A. 3 -2077.911376953125 -2077.899169921875\r\n",
      "N.A. 5 -1101.7099609375 -1101.574462890625\r\n",
      "N.A. 4 -1537.5460205078125 -1537.413330078125\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 {panna_cmdir+'/doc/tutorial/myvalidation/epoch_10_step_1000.dat'}\n",
    "# not printing out the filename or key to keep the files lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00029-876e51f0-656c-4366-8cc8-3fbd9376098a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 143,
    "execution_start": 1636952708345,
    "source_hash": "482b71b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv(panna_dir+'/doc/tutorial/myvalidation/epoch_10_step_1000.dat', delim_whitespace=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00030-4706edc9-5f00-4c10-b3d5-f20c4a079de5",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     264
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 286,
    "execution_start": 1636952717262,
    "source_hash": "64bc8529",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pandas have useful plotting tools but if you want to stick to matplotlib:\n",
    "plt.plot((df['e_ref'] -df['e_nn'])/df['n_atoms'], 'b.')\n",
    "plt.ylabel('DFT - ANN (eV/atom)')\n",
    "plt.xlabel('config. index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to cleanup the tutorial directory\n",
    "# (do not remove these files if you want to follow part 3, converting the network to a lammps potential)\n",
    "!cd {panna_cmdir+'/doc/tutorial'}; rm -rf mytrain mytrain_logs myvalidation tf.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
